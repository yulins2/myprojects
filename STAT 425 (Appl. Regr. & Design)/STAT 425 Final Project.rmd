---
title: "STAT 425 Final Project"
author: "Yulin Song (yulins2), section A3"
date: "Mar 17 2021"
output: pdf_document
---

\newpage

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 5.5, fig.height = 2.8, message = FALSE, warning = FALSE)
```

# Summary Statistics & Histograms

```{r}

# read the table and convert all number 
data <- read.csv("Food_Supply_kcal_Data.csv")
n = ncol(data)
data[,2:(n-1)] <- lapply(data[,2:(n-1)], function(data) as.numeric(data))
attach(data)

# getting the pairwise correlation of 25 diet columns and the response "death"
mod <- data[,c(2:26,28)]


#corr_mod <- cor(na.omit(mod))
#pair wise correlation 
corr_mod <- cor(mod, use = "pairwise.complete.obs")
corr_mod

# summary statistics of the 26 columns (Figure 1 in report)
sum_mod <- summary(mod)
sum_mod

# histogram of the 26 columns (Figure 2 in report)
n_breaks = 35
for (i in 1:23) {
hist(mod[,i],main = c("Histogram of",colnames(mod[i])), 
     xlab = "% of total energy (kcal)", breaks = n_breaks)
}
for (i in 24:26) {
hist(mod[,i],main = c("Histogram of",colnames(mod[i])), 
     xlab = "% of total national population", breaks = n_breaks)
}


```

# Correlation Plot and High correlation entries

```{r corrplot_mod, fig.width = 10, fig.height = 7}

# pairwise correlation Plot (Figure 3 in report)
library(corrplot)
corrplot_mod <- corrplot(corr_mod, type = 'upper')

# which column & rows in corr_mod where absolute value of correlation happens to be >= 0.75

## indices of the above criteria happens 
## (counted in each column from top to bottom and then across columns from left to right)

(highcorr_indices <- which(abs(corr_mod) >= 0.75 & corr_mod < 1))
(columns_length <- length(corr_mod[1,]))

## "which rows" is calculated by:
## ind mod col_length
(rows_indices <- highcorr_indices %% columns_length)

## "which columns" is calculated by:
(cols_indices <- 1 + ((highcorr_indices - rows_indices) / columns_length))

# correlation between Meat and Animal Products
corr_mod[9,2]

# correlation between Vegetal Products and Animal Products
corr_mod[21,2]

# correlation between Vegetal Products and Meat
corr_mod[21,9]

# in corr_plot, (9,2) and (2,9) corresponds to Meat&Animal Products; (high positive correlation)
# (21,2) and (2,21) corresponds to Vegetal Products&Animal Products; (high negative correlation)
# (21,9) and (9,21) corresponds to Vegetal Products & Meat. (high positive correlation)
# These three pairs have pairwise high correlation

```

# Multiple Linear Regression

```{r, fig.height=5.8}

# multiple linear regression using all predictors
############## We will use full model firstly to predict, name (Full Model) in report.

#too much missing of Undernourished, not appropriate to drop all of the 
#observations that just missing of Undernourished
#51/170 missing proportion is about 30% which is too high, we can just drop it
mod$Undernourished <- NULL

#then we can remove missing values of observations
mod2 <- na.omit(mod)
#now we have 163 data only 7 removed from original data, if we just remove 
#all missing values, we only get 112 observations, we would lost information from over 50 observations
#which is not appropriate, so drop Undernourished first is a better choice
dim(mod2) 


set.seed(1)

id <- sample(1:nrow(mod2), 0.8*nrow(mod2))
traindata <- mod2[id, ]
testdata <- mod2[-id,]



full_model <- lm(Deaths ~ ., data = traindata)
summary(full_model)

#too much insignificant predictors and model diagnostics:

par(mfrow = c(2,2))
plot(full_model,1:4)
par(mfrow = c(1,1))

#Check model assumptions:

#1) independent assumption: the points are randomly distributed around the zero mean line, it is true. 

#2) linearity assumption: the residuals plot shows there is no special curve, the linearity asumption is true.

#3) constant variance assumption: the residuals plot also shows  the spread of residuals changes across x-axis obviously, it is not true, it becomes larger obviously


#4) normality assumption: the normal qq plot shows that some outliers far from  the line at the two tails,  the normality assumption is also questionable


#use transformation



#add 0.00001 to avod log(0)

log_full_model <- lm( log(Deaths + 0.00001)  ~ ., data = traindata)
summary(log_full_model)

#too much insignificant predictors and model diagnostics:

par(mfrow = c(2,2))
plot(log_full_model,1:4)
par(mfrow = c(1,1))

#assumptions much better, no serious issues now, but we need perform model selections

# Before that, do prediction

# but before that, we will try to predict 

pred_1 <- predict(log_full_model, testdata)
pred_1 <- exp(pred_1) -  1e-05
mse_1 <- mean((pred_1 - testdata$Deaths)^2)
mse_1


```


```{r, fig.height=5.6}
aic <- step(log_full_model, trace = 0)
bic <-  step(log_full_model, trace = 0, k = log(nrow(traindata)))
summary(aic)
summary(bic)

#it seems BIC selected model is better, all predictors are significant, the R-squared value
#is not lower too much compared with full model

#model diagnostics:

par(mfrow = c(2,2))
plot(bic,1:4)
par(mfrow = c(1,1))

#Check model assumptions:

#1) independent assumption: the points are randomly distributed around the zero mean line, it is true. 

#2) linearity assumption: the residuals plot shows there is no special curve, the linearity asumption is true.

#3) constant variance assumption: the residuals plot also shows  the spread of residuals does not changes across x-axis obviously, it is true


#4) normality assumption: the normal qq plot shows that only some outliers far from  the line at the two tails, overall, fits the line well, so the  the normality assumption can be true  

```


```{r, fig.height=5.6}
#then we need to check unusual points

n = dim(traindata)[1]

outliers <- which(abs(rstudent(bic)) > 2.5)
outliers 
highleverages <- which(hatvalues(bic) >  2 * mean(hatvalues(bic)  ))
highleverages 
stronginfluences <- which(cooks.distance(bic) > 4 / (nrow(traindata) - length(coef(bic))))
stronginfluences 

#remove them

ids <- unique(c(outliers ,highleverages ,stronginfluences ))


bic2 <- lm(formula = log(Deaths + 1e-05) ~ Alcoholic.Beverages + Animal.fats + 
    Cereals...Excluding.Beer + Eggs + Fruits...Excluding.Wine + 
    Milk...Excluding.Butter + Starchy.Roots + Sugar...Sweeteners + 
    Treenuts + Vegetable.Oils, data = traindata[-ids, ])

summary(bic2)


#model diagnostics check, this potentially can be used as final best model
library(lmtest)
dwtest(bic2)
bptest(bic2)
shapiro.test(residuals(bic2))
#both p values are larger than 0.05, so the residauls have constant variance and to be normality,
#so linear model is valid


#predictions


pred_2 <- predict(bic2, testdata)
pred_2 <- exp(pred_2) -  1e-05
mse_2 <- mean((pred_2 - testdata$Deaths)^2)
mse_2

# BIC2 Model: Adjusted R^2 0.6297; Predicted MSE: 0.00635

```

```{r}
#use PCA

XX <- mod2[,-ncol(mod2)]

pca <- princomp(XX)

summary(pca) # first 4 PCS already explain  0.93623305 that 93.6% percent of variance in original data

plot(pca, type = "l")
#use the first 4 principle compoents is appropriate
#as it is an elbow point that after this point, the decrease is very slow 

#interpret which variables contribute to the 4 PCS, the larger 
#the absolute coefficients, the more important in the corresponding PC
#for example, Obesity  , Cereals...Excluding.Beer ,Animal.Products ,Vegetal.Products  are most #important in PC1, others are not
round(pca$loadings[,1:4],2)


#then use the first 4 PCs  to build regression model
newmod <- data.frame(Deaths = mod2$Deaths, pca$scores[,1:4])
traindata_pca <-  newmod [id, ]
testdata_pca <- newmod[-id,]


pca_model <- lm(Deaths ~ ., data = traindata_pca)
summary(pca_model)

pred <- predict(pca_model, testdata_pca)

mse_pca <- (mean((pred - testdata_pca$Deaths)^2))
mse_pca
#MSE is low
```



```{r}
#random forest model

library(caret)
set.seed(1)


#first use 5-folds cross validation to find the best model

ctrl <- trainControl(method = "cv", 
                     number = 5)

#as random forest is not like  linear model, it does not require normality and etc, so 
#we can just use deaths as response

fit <- train(Deaths ~ ., data = traindata,
             method = "rf",
             tuneLength = 15,
             trControl = ctrl)

fit

plot(fit)

#the best parameter mtry is 6, RMSE is lowest 


#check variables important plot to find which predictors affect the deaths seriously,
#the top ones are most important ones
plot(varImp(fit))


#predictions


pred <- predict(fit, testdata)

mse2 <- (mean((pred - testdata$Deaths)^2))
mse2
#MSE is much lower, so the model performs much better than linear model
```






